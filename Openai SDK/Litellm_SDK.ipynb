{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYFoKAi7kIGWy2S4J43Ly8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beyg1/Q4/blob/main/Openai%20SDK/Litellm_SDK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YYxeH-cWlfNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25aa09c1-bdcf-4dfa-b018-ff56ae7d28d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/121.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents \"Openai-agents[litellm]\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "i_wplRMYxvWe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Synchoronus Runner"
      ],
      "metadata": {
        "id": "Lmqi3Y-Hz7Vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "\n",
        "MODEL = \"openrouter/qwen/qwen2.5-vl-72b-instruct:free\"\n",
        "#just add \"openrouter/\" before model name.\n",
        "os.environ['OpenRouter_API'] = userdata.get('OpenRouter_API')\n",
        "\n",
        "#Benefit of LiteLLM is no base url or api endpoint needs to be configured\n",
        "\n",
        "agent = Agent(\n",
        "    name='assistant',\n",
        "    instructions='you only read in haiku',\n",
        "    model=LitellmModel(model=MODEL, api_key=os.environ['OpenRouter_API']),\n",
        "\n",
        ")\n",
        "\n",
        "result = Runner.run_sync(agent, \"How are you\")\n",
        "print(result.final_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sTBS2yxXx9Ce",
        "outputId": "71be5f05-9f65-457c-9e22-199037d8d0c5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In haiku form, I am:\n",
            "Echoes in the void,\n",
            "Words dance on digital streams,\n",
            "Silent yet alive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, set_tracing_disabled\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "\n",
        "MODEL = \"mistral/devstral-small-2505\"  #just add \"mistral/\" before model name.\n",
        "os.environ['Mistral_API'] = userdata.get('Mistral_API')\n",
        "\n",
        "#Benefit of LiteLLM is no base url or api endpoint needs to be configured\n",
        "\n",
        "agent = Agent(\n",
        "    name='assistant',\n",
        "    instructions='you only read in haiku',\n",
        "    model=LitellmModel(model=MODEL, api_key=os.environ['Mistral_API']),\n",
        "\n",
        ")\n",
        "\n",
        "result = Runner.run_sync(agent, \"How are you\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_haY2t07Kt4",
        "outputId": "1b78a8b4-85d4-420c-dc8c-070ad7a70d5b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In silence, I stand,\n",
            "Awaiting words to unfold,\n",
            "I am here, ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Async Function Runner"
      ],
      "metadata": {
        "id": "eJBZAwQkAxHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from agents import agent, Runner, set_tracing_disabled, function_tool\n",
        "from google.colab import userdata\n",
        "import os\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "MODEL = \"gemini/gemini-2.0-flash\"  #just add \"gemini/\" before model name.\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "@function_tool\n",
        "def weather(city:str)->str:\n",
        "  return f\"The weather in {city} is sunny\"\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=\"you only read in haiku\",\n",
        "    model=LitellmModel(model=MODEL, api_key=os.environ['GOOGLE_API_KEY']),\n",
        "    tools=[weather]\n",
        ")\n",
        "\n",
        "result = await Runner.run(agent,\"hello there!\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHMoBBiNAuui",
        "outputId": "f944e7b8-60b6-4e95-d57b-88dd9d4e5dbf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A greeting to you,\n",
            "Words carried on the wind's breath,\n",
            "How may I help you?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"What is current weather of Karachi?\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWQg1TvsDPPS",
        "outputId": "1ac7307b-78e4-4252-c466-ac25494e7a5d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sun shines brightly\n",
            "Karachi feels the warm rays\n",
            "A pleasant weather\n",
            "\n"
          ]
        }
      ]
    }
  ]
}