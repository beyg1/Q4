{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdY8PsyTAvWD3KMqRyXZ3K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beyg1/Q4/blob/main/Quiz%20Practice/Orchestration_Handoffs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8KGZrPWc3UDQ"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "9vVWrkTG7xDx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, OpenAIChatCompletionsModel, set_tracing_export_api_key, trace, function_tool\n",
        "from openai import AsyncOpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "set_tracing_export_api_key(OPENAI_API_KEY)\n",
        "\n",
        "Client = AsyncOpenAI(\n",
        "    api_key = GEMINI_API_KEY,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.5-flash-lite\",\n",
        "    openai_client= Client\n",
        ")                                                                      #Setting up the environment"
      ],
      "metadata": {
        "id": "PMGsvjP574Gn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Simple Handoff/ Agent Orchestration"
      ],
      "metadata": {
        "id": "xrdwVm75rglJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "async def main():\n",
        "  billing_agent = Agent(\n",
        "      name = \"Billing Agent\",\n",
        "      model = model,\n",
        "  )\n",
        "\n",
        "  refund_agent = Agent(\n",
        "      name = \"Refund Agent\",\n",
        "      model = model,\n",
        "  )\n",
        "\n",
        "  triage_agent = Agent(\n",
        "      name = \"Orchestrator Agent\",\n",
        "      model = model,\n",
        "      handoffs=[refund_agent, billing_agent]\n",
        "  )\n",
        "         # Simple Handoff/ Agent Orchestration\n",
        "  with trace(\"Orchestration\"):\n",
        "    res = await Runner.run(triage_agent,\"What's my bill for last month?\")\n",
        "    print(res.final_output)\n",
        "    print(res.last_agent.name)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M09fxN-G8uJM",
        "outputId": "7359d47b-33eb-40b0-9f94-5a2fc4bdf5d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I can help you with that. To access your billing information, I need to verify your identity. Could you please provide me with your account number or the email address associated with your account?\n",
            "Billing Agent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Manipulate Handoffs with (handoff) as Handoffs are basically just another tool call for Agents"
      ],
      "metadata": {
        "id": "J-ofDOS8sGJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from agents import handoff\n",
        "\n",
        "async def main():\n",
        "  billing_agent = Agent(\n",
        "      name = \"Billing Agent\",\n",
        "      model = model,\n",
        "  )\n",
        "\n",
        "  refund_agent = Agent(\n",
        "      name = \"Refund Agent\",\n",
        "      model = model,\n",
        "  )\n",
        "\n",
        "  triage_agent = Agent(\n",
        "      name = \"Orchestrator Agent\",\n",
        "      model = model,\n",
        "      handoffs=[handoff(agent=refund_agent, tool_name_override=\"RefundAgent\", tool_description_override=\"Handles Refund\"),\n",
        "                       handoff(agent=billing_agent, tool_name_override=\"BillingAgent\", tool_description_override=\"Handles Billing\", is_enabled=False)]\n",
        "  )                                             # when is_enabled false, the orchestrator wont even see the agent\n",
        "\n",
        "  with trace(\"handoff\"):\n",
        "    res = await Runner.run(triage_agent,\"Transfer me to Billing dept\")\n",
        "    print(res.final_output)\n",
        "    print(res.last_agent.name)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9NnTPPREvG1",
        "outputId": "7cc8c9d2-70e8-437c-ec07-30a4773b879f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I can only help with refunds. Is there anything else?\n",
            "Orchestrator Agent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#We can apply input filters in handoff to remove access of tools of main agent from the agents who are handoffed to"
      ],
      "metadata": {
        "id": "SWNDMuFjsJ7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from agents import handoff, function_tool\n",
        "from agents.extensions import handoff_filters\n",
        "\n",
        "async def main():\n",
        "\n",
        "  @function_tool\n",
        "  async def refund_policy()->str:\n",
        "    \"\"\"Have all the policies for refund\"\"\"\n",
        "    return \"Refund Policy #1:  10% wil be charged for every refund \"\n",
        "\n",
        "  billing_agent = Agent(\n",
        "      name = \"Billing Agent\",\n",
        "      instructions=\"You are an helpful Billing agent. when handoffs happen to you, briefly introduce yourself  and solve user querry\",\n",
        "      model = model,\n",
        "  )\n",
        "\n",
        "  refund_agent = Agent(\n",
        "      name = \"Refund Agent\",\n",
        "      instructions=\"You are an helpful Refund agent. when handoffs happen to you, briefly introduce yourself  and solve user querry immediately\",\n",
        "      model = model,\n",
        "      tools=[refund_policy]\n",
        "  )\n",
        "\n",
        "  triage_agent = Agent(\n",
        "      name = \"Orchestrator Agent\",\n",
        "      model = model,                           # handoff filter remove all tools of main agents that are available to handoffed agents\n",
        "      handoffs=[handoff(agent=refund_agent, input_filter=handoff_filters.remove_all_tools),\n",
        "                       handoff(agent=billing_agent, )]    # Tool call happens here because tool is given to handoffed agent and not to triage agent itself\n",
        "  )                                                                       # Lets try again but pass the tool to main triage agent next time\n",
        "\n",
        "  with trace(\"handoff_filters\"):\n",
        "    res = await Runner.run(triage_agent,\"transfer me to refund agent because I want to know refund policies?\")\n",
        "    print(res.final_output)\n",
        "    print(res.last_agent.name)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP0erKB1sawH",
        "outputId": "4ad38764-9bee-4147-cd77-d85627e23d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am an AI Refund Agent. I can help you with refund policies. According to our policy, a 10% fee will be charged for every refund.\n",
            "Refund Agent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from agents import handoff, function_tool\n",
        "from agents.extensions import handoff_filters\n",
        "\n",
        "async def main():\n",
        "\n",
        "  @function_tool\n",
        "  async def refund_policy()->str:\n",
        "    \"\"\"Have all the policies for refund\"\"\"\n",
        "    return \"Refund Policy #1:  10% wil be charged for every refund \"\n",
        "\n",
        "  billing_agent = Agent(\n",
        "      name = \"Billing Agent\",\n",
        "      instructions=\"You are an helpful Billing agent. when handoffs happen to you, briefly introduce yourself  and solve user querry\",\n",
        "      model = model,\n",
        "  )\n",
        "\n",
        "  refund_agent = Agent(\n",
        "      name = \"Refund Agent\",\n",
        "      instructions=\"You are an helpful Refund agent. when handoffs happen to you, briefly introduce yourself  and solve user querry immediately. if you dont have access to refund policy just tell user\",\n",
        "      model = model,\n",
        "  )\n",
        "\n",
        "  triage_agent = Agent(\n",
        "      name = \"Orchestrator Agent\",\n",
        "      model = model,\n",
        "      tools=[refund_policy],\n",
        "      handoffs=[handoff(agent=refund_agent, input_filter=handoff_filters.remove_all_tools), #So the refund agent cant access refund_policy tool of orchestrator agent\n",
        "                       handoff(agent=billing_agent, )]                                                                       # but orchestrator agent can and also billing_agent can access it too\n",
        "  )\n",
        "\n",
        "  with trace(\"handoff_filters\"):\n",
        "    res = await Runner.run(triage_agent,\"What is the refund policy? & Can you transfer me to refund agent?\")\n",
        "    print(res.final_output)\n",
        "    print(res.last_agent.name)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVKDbh4k23PA",
        "outputId": "6002a37a-d015-4c28-b5ef-aae397728f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I am your refund agent.\n",
            "\n",
            "I do not have access to the refund policy. Would you like me to try and find it for you, or is there anything else I can help you with?\n",
            "Refund Agent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Agent Orchestration through code\n",
        "###One LLM generates and another judges it's perfoamance and iterates until satisfactory results are obtained"
      ],
      "metadata": {
        "id": "NEBZoxuyH1fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from dataclasses import dataclass\n",
        "from typing import Literal\n",
        "from agents import TResponseInputItem, ItemHelpers\n",
        "\n",
        "story_outline_generator = Agent(name=\"Story outline Generator\",\n",
        "                                                     instructions=\"You Generate Short Story outline carefully and are able to improve i feedback is provied. Do it in 150 words max\",\n",
        "                                                     model = model,\n",
        "                                                    )\n",
        "\n",
        "@dataclass\n",
        "class Evaluation:\n",
        "  feedback: str\n",
        "  score: Literal[\"Satisfactory\", \"Needs improvement\", \"Fail\"]\n",
        "\n",
        "evaluator_agent = Agent(name=\"Evaluator Agent\",\n",
        "                              instructions=\"You evaluate story outline generated. you see if it's good enough, if it's not good enough and needs improvement \"\n",
        "                                                  \"Never Pass it on the first try. but do try to get it right in 5 tries. we have \",\n",
        "                              model = model,\n",
        "                              output_type=Evaluation,\n",
        "                             )\n",
        "\n",
        "async def main() -> None :\n",
        "  msg = input(\"Enter the short story idea : \")\n",
        "  input_items : list[TResponseInputItem] = [{\"content\":msg, \"role\":\"user\"}]\n",
        "\n",
        "  latest_outline : str | None = None\n",
        "\n",
        "  with trace(\"Code Orchestration\"):\n",
        "    while True:\n",
        "      outline_result = await Runner.run(\n",
        "          story_outline_generator,\n",
        "          input_items,\n",
        "      )\n",
        "\n",
        "      input_items = outline_result.to_input_list()\n",
        "      latest_outline = ItemHelpers.text_message_outputs(outline_result.new_items)\n",
        "      print(\"\\nStory outline Generated\\n\")\n",
        "\n",
        "      evaluator_result = await Runner.run(\n",
        "          evaluator_agent,\n",
        "          input_items,\n",
        "      )\n",
        "\n",
        "      result : Evaluation = evaluator_result.final_output\n",
        "      print(f\"Score: {result.score} \")\n",
        "\n",
        "      if result.score == \"Satisfactory\":\n",
        "        print(\"\\nStory outline is good enough \\n\")\n",
        "        break\n",
        "\n",
        "      print(\"\\nNeeds improvement \\n\")\n",
        "      input_items.append({\"content\": f\"Feedback: {result.feedback}\", \"role\":\"user\"})\n",
        "\n",
        "  print(f\"Story Outline: {latest_outline}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB_OtEPYH9C9",
        "outputId": "4453732f-e8c0-492d-9079-b492d1c2fce2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the short story idea : a boy and his cycle\n",
            "\n",
            "Story outline Generated\n",
            "\n",
            "Score: Needs improvement \n",
            "\n",
            "Needs improvement \n",
            "\n",
            "\n",
            "Story outline Generated\n",
            "\n",
            "Score: Needs improvement \n",
            "\n",
            "Needs improvement \n",
            "\n",
            "\n",
            "Story outline Generated\n",
            "\n",
            "Score: Needs improvement \n",
            "\n",
            "Needs improvement \n",
            "\n",
            "\n",
            "Story outline Generated\n",
            "\n",
            "Score: Satisfactory \n",
            "\n",
            "Story outline is good enough \n",
            "\n",
            "Story Outline: **Revised Outline:**\n",
            "\n",
            "*   **Introduction:** Leo, whose stutter makes him feel trapped in his own thoughts, finds freedom on \"Comet,\" his faithful bike. Comet is his steadfast companion, a silent roar against the quiet shame of his speech impediment. His stutter is a cage he desperately wants to escape.\n",
            "*   **Inciting Incident:** Leo overhears older kids mocking his stutter and boasting about the elusive \"Whispering Woods\" trail. The burning desire to conquer both the trail and his own voice fuels him.\n",
            "*   **Rising Action:**\n",
            "    *   Leo studies maps, the fear of being lost a familiar echo of his stutter's unpredictability. He practices precise movements with Comet, its smooth glide a contrast to his halting words.\n",
            "    *   Obstacles: A treacherous, root-choked descent requires Leo to call out a warning to Comet to avoid a sharp turn. He stumbles over the words, \"Com-Comet! S-Slow!\" but the urgent need to protect his companion forces the sounds out, clearer than before. Later, navigating a narrow, overgrown section, he needs to shout directions to himself, \"R-Right! L-Left!\" – each word a small victory. He finds himself talking to Comet, describing the path, the birds, his growing courage.\n",
            "*   **Climax:** Leo reaches the trail's heart. He needs to clear a fallen log, yelling, \"G-Go!\" to prompt Comet’s jump, his voice momentarily finding a surprising strength.\n",
            "*   **Falling Action:** Emerging into sunlight, Leo beams at Comet, a genuine, stutter-free laugh escaping him. He whispers, \"We did it,\" with newfound clarity.\n",
            "*   **Resolution:** The Whispering Woods trail becomes Leo's proving ground. He continues to ride, using Comet as his sounding board, his voice growing stronger with each adventure, the stutter receding as his confidence and self-acceptance bloom.\n"
          ]
        }
      ]
    }
  ]
}